wandb_version: 1

components:
  desc: null
  value:
    ner:
      factory: ner
      incorrect_spans_key: null
      moves: null
      scorer:
        '@scorers': spacy.ner_scorer.v1
      update_with_oracle_cut_size: 100
      model:
        '@architectures': spacy.TransitionBasedParser.v1
        state_type: ner
        extra_state_tokens: false
        hidden_width: 64
        maxout_pieces: 2
        use_upper: true
        'no': null
        tok2vec:
          '@architectures': spacy.Tok2VecListener.v1
          width: 96
          upstream: '*'
    tok2vec:
      factory: tok2vec
      model:
        '@architectures': spacy.Tok2Vec.v1
        embed:
          '@architectures': spacy.MultiHashEmbed.v1
          width: 96
          rows:
          - 2000
          - 1000
          - 1000
          - 1000
          attrs:
          - NORM
          - PREFIX
          - SUFFIX
          - SHAPE
          include_static_vectors: false
        encode:
          '@architectures': spacy.MaxoutWindowEncoder.v1
          width: 96
          depth: 4
          window_size: 1
          maxout_pieces: 3
corpora:
  desc: null
  value:
    dev:
      '@readers': spacy.Corpus.v1
      max_length: 0
      gold_preproc: false
      limit: 0
      augmenter: null
    train:
      '@readers': spacy.Corpus.v1
      max_length: 2000
      gold_preproc: false
      limit: 0
      augmenter: null
initialize:
  desc: null
  value:
    vectors: null
    init_tok2vec: null
    vocab_data: null
    lookups: null
    before_init: null
    after_init: null
nlp:
  desc: null
  value:
    lang: en
    pipeline:
    - tok2vec
    - ner
    tokenizer:
      '@tokenizers': spacy.Tokenizer.v1
    before_creation: null
    after_creation: null
    after_pipeline_creation: null
    disabled: []
    batch_size: 500
paths:
  desc: null
  value:
    raw: null
    init_tok2vec: null
    vectors: null
system:
  desc: null
  value:
    gpu_allocator: null
    seed: 0
training:
  desc: null
  value:
    train_corpus: corpora.train
    dev_corpus: corpora.dev
    seed: 0
    gpu_allocator: null
    dropout: 0.1
    accumulate_gradient: 1
    patience: 1600
    max_epochs: 0
    max_steps: 20000
    eval_frequency: 200
    frozen_components: []
    before_to_disk: null
    annotating_components: []
    before_update: null
    batcher:
      '@batchers': spacy.batch_by_words.v1
      discard_oversize: false
      tolerance: 0.2
      get_length: null
      size:
        '@schedules': compounding.v1
        start: 100
        stop: 1000
        compound: 1.001
        t: 0.0
    logger:
      '@loggers': spacy.WandbLogger.v1
      project_name: monitor_proglang_training
      remove_config_values:
      - paths.train
      - paths.dev
      - corpora.train.path
      - corpora.dev.path
    optimizer:
      '@optimizers': Adam.v1
      beta1: 0.9
      beta2: 0.999
      l2_is_weight_decay: true
      l2: 0.01
      grad_clip: 1.0
      use_averages: false
      eps: 1.0e-08
      learn_rate:
        '@schedules': warmup_linear.v1
        warmup_steps: 250
        total_steps: 20000
        initial_rate: 5.0e-05
    score_weights:
      ents_f: 1.0
      ents_p: 0.0
      ents_r: 0.0
      ents_per_type: null
_wandb:
  desc: null
  value:
    python_version: 3.9.12
    cli_version: 0.17.3
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1720189578
    t:
      1:
      - 1
      - 2
      - 3
      - 33
      - 55
      - 104
      2:
      - 1
      - 2
      - 3
      - 33
      - 55
      - 104
      3:
      - 2
      - 16
      - 23
      4: 3.9.12
      5: 0.17.3
      8:
      - 4
      - 5
      13: darwin-arm64
